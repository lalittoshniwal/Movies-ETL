# Movies-ETL

## Purpose
The purpose of this analysis was to help Amazing Video prepare for a hackathon. To do this, I followed the ETL process using Jupyter Notebook and Postgress: extracted the files from both Wikipedia (JSON) and Kaggle (CSVs) into Jupyter Notebook, transformed the datasets by cleaning them up and joining them together, and loaded the cleaned dataset into Postgress.

## Results
I was succesfully able to extract, transform and load the data. As follows are the screenshots of queries in Postgress.

 <img src="/Resources/movies_query.png" >

 <img src="/Resources/ratings_query.png" >
